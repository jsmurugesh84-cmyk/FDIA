{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bO20qQYEbvFm"
      },
      "outputs": [],
      "source": [
        "#GAN\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, precision_score, recall_score, f1_score\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, RepeatVector, TimeDistributed, LeakyReLU, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "# Define a function to evaluate models and store results\n",
        "def evaluate_model(model_name, y_true, y_pred, y_score, fit_time, predict_time):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    roc_auc = roc_auc_score(y_true, y_score) if y_score is not None else np.nan\n",
        "\n",
        "    return {\n",
        "        'Model': model_name,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1-Score': f1,\n",
        "        'ROC-AUC': roc_auc\n",
        "    }\n",
        "\n",
        "# Initialize a DataFrame to store results\n",
        "results = pd.DataFrame(columns=[\n",
        "    'Model', 'Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC'\n",
        "\n",
        "])\n",
        "\n",
        "# Load and prepare data\n",
        "data = pd.read_csv('/content/14bus_fdia_combined_dataset_overall.csv')\n",
        "\n",
        "# Feature engineering\n",
        "X = data.drop(['attack', 'bus', 'load_percentage', 'varied_load', 'voltage_increase', 'angle_increase'], axis=1)\n",
        "y = data['attack']\n",
        "\n",
        "# Split data (keeping temporal order for LSTM)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Standardize data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# MinMax scaler for GANs\n",
        "minmax_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "X_train_minmax = minmax_scaler.fit_transform(X_train)\n",
        "X_test_minmax = minmax_scaler.transform(X_test)\n",
        "\n",
        "\n",
        "# ======================\n",
        "# 3. GAN-based Detection\n",
        "# ======================\n",
        "print(\"\\nTraining GAN models...\")\n",
        "\n",
        "# Common GAN components\n",
        "def build_generator(latent_dim, output_dim):\n",
        "    model = Sequential([\n",
        "        Dense(128, input_dim=latent_dim),\n",
        "        LeakyReLU(alpha=0.2),\n",
        "        Dense(256),\n",
        "        LeakyReLU(alpha=0.2),\n",
        "        Dense(output_dim, activation='tanh')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def build_discriminator(input_dim):\n",
        "    model = Sequential([\n",
        "        Dense(256, input_dim=input_dim),\n",
        "        LeakyReLU(alpha=0.2),\n",
        "        Dropout(0.3),\n",
        "        Dense(128),\n",
        "        LeakyReLU(alpha=0.2),\n",
        "        Dropout(0.3),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# ======================\n",
        "# 3.1  GAN\n",
        "# ======================\n",
        "def train_gan(X_train, latent_dim=100, epochs=1400, batch_size=64):\n",
        "    input_dim = X_train.shape[1]\n",
        "\n",
        "    # Build and compile discriminator\n",
        "    discriminator = build_discriminator(input_dim)\n",
        "    discriminator.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5), metrics=['accuracy'])\n",
        "\n",
        "    # Build generator\n",
        "    generator = build_generator(latent_dim, input_dim)\n",
        "\n",
        "    # Combined model\n",
        "    z = Input(shape=(latent_dim,))\n",
        "    generated = generator(z)\n",
        "    discriminator.trainable = False\n",
        "    validity = discriminator(generated)\n",
        "    combined = Model(z, validity)\n",
        "    combined.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5))\n",
        "\n",
        "    # Adversarial ground truths\n",
        "    valid = np.ones((batch_size, 1))\n",
        "    fake = np.zeros((batch_size, 1))\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Train discriminator\n",
        "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "        real_samples = X_train[idx]\n",
        "\n",
        "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "        gen_samples = generator.predict(noise)\n",
        "\n",
        "        d_loss_real = discriminator.train_on_batch(real_samples, valid)\n",
        "        d_loss_fake = discriminator.train_on_batch(gen_samples, fake)\n",
        "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "        # Train generator\n",
        "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "        g_loss = combined.train_on_batch(noise, valid)\n",
        "\n",
        "        if epoch % 100 == 0:\n",
        "            print(f\"Epoch {epoch} [D loss: {d_loss[0]:.4f}, acc: {100*d_loss[1]:.2f}%] [G loss: {g_loss:.4f}]\")\n",
        "\n",
        "    return generator, discriminator\n",
        "\n",
        "print(\"\\nTraining Standard GAN...\")\n",
        "gan_generator, gan_discriminator = train_gan(X_train_minmax)\n",
        "\n",
        "# Anomaly detection with GAN\n",
        "def gan_anomaly_detection(X_test, generator, discriminator, latent_dim=100, n_samples=1000):\n",
        "    # Generate synthetic normal samples\n",
        "    noise = np.random.normal(0, 1, (n_samples, latent_dim))\n",
        "    generated_samples = generator.predict(noise)\n",
        "\n",
        "    # Calculate discriminator scores for real and generated samples\n",
        "    real_scores = discriminator.predict(X_test)\n",
        "    gen_scores = discriminator.predict(generated_samples)\n",
        "\n",
        "    # Calculate anomaly scores\n",
        "    anomaly_scores = 1 - real_scores.flatten()\n",
        "    threshold = np.percentile(1 - gen_scores.flatten(), 95)\n",
        "\n",
        "    return anomaly_scores, threshold\n",
        "\n",
        "gan_scores, gan_threshold = gan_anomaly_detection(X_test_minmax, gan_generator, gan_discriminator)\n",
        "gan_pred = (gan_scores > gan_threshold).astype(int)\n",
        "\n",
        "print(\"\\nGAN Results:\")\n",
        "print(classification_report(y_test, gan_pred))\n",
        "print(f\"Accuracy: {accuracy_score(y_test, gan_pred):.4f}\")\n",
        "print(f\"precision: {precision_score(y_test, gan_pred):.4f}\")\n",
        "print(f\"recall: {recall_score(y_test, gan_pred):.4f}\")\n",
        "print(f\"f1-score: {f1_score(y_test, gan_pred):.4f}\")\n",
        "\n",
        "# ======================\n",
        "# ROC Curve for GAN\n",
        "# ======================\n",
        "\n",
        "# Calculate ROC-AUC\n",
        "gan_roc_auc = roc_auc_score(y_test, gan_scores)\n",
        "\n",
        "# Compute ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, gan_scores)\n",
        "\n",
        "print(f\"ROC-AUC Score: {gan_roc_auc:.4f}\")\n",
        "\n",
        "# Plot ROC Curve\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr)\n",
        "plt.plot([0, 1], [0, 1])\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve - GAN\")\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}